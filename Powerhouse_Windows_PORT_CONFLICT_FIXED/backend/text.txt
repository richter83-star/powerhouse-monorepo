SPEC-1-B2B-17-Agent-Platform

Background

Goal: evolve the current 17-agent demo suite into a B2B, multi-tenant platform that delivers repeatable ROI on defined workflows (Compliance Intelligence, Customer Success Intelligence).

⸻

Requirements

Must-Have
	•	Agent Core:
	•	Each of 17 agent modules upgraded to support LLM API calls (OpenAI/Anthropic/Cohere).
	•	JSON-structured outputs (not only strings).
	•	Persistence:
	•	Postgres with vector search (pgvector or external vector DB) for memory + audit logs.
	•	Multi-Tenancy:
	•	User auth (OAuth/SAML) and per-tenant DB isolation.
	•	APIs:
	•	REST or GraphQL endpoints to submit tasks and retrieve results.
	•	Security:
	•	Secrets management (Kubernetes Secrets + Vault optional).
	•	TLS everywhere, audit logs, role-based access.
	•	Deployment:
	•	Containerized (Docker), orchestrated (K8s), with Helm chart.
	•	CI/CD pipeline builds and tests containers.
	•	Compliance Vertical MVP:
	•	Workflow: ingest policy text → multi-agent analysis → compliance risk matrix.
	•	Customer Success Vertical MVP:
	•	Workflow: ingest feedback logs → multi-agent processing → churn risk + action plan.

Should-Have
	•	Ingress with TLS + custom domain per tenant.
	•	Admin dashboard (Streamlit or React web app) for results.
	•	API rate limiting per tenant.
	•	Mobile companion app (Flutter/React Native) connecting to backend API.
	•	Observability: Prometheus/Grafana + error tracking (Sentry).

Could-Have
	•	Hybrid execution: on-device lightweight inference for mobile (summaries, embeddings).
	•	Plugin framework for external tools (Slack, Jira, Salesforce connectors).
	•	Natural language task orchestration (“Agent Team, do X”).

Method
Architecture overview
	•	API: REST/JSON over HTTPS. Auth via OAuth2/OIDC.
	•	Orchestrator: Temporal workflows for durable, resumable multi-agent runs.
	•	Agents Runtime: 17 agents as stateless workers. gRPC/HTTP calls to LLMs.
	•	Queue: Temporal task queues (alternatively RabbitMQ).
	•	Storage: Postgres 15 + pgvector for memory and retrieval. S3-compatible object store for artifacts.
	•	Cache: Redis for short-lived prompts/results.
	•	Observability: Prometheus + Grafana, app logs to ELK or OpenSearch.

PlantUML — components

@startuml
skinparam componentStyle rectangle
package "B2B Agent Platform" {
  [API Gateway] --> [Orchestrator (Temporal)]
  [Orchestrator (Temporal)] --> [Task Queue]
  [Task Queue] --> [Agent Workers xN]
  [Agent Workers xN] --> [LLM Providers]
  [Agent Workers xN] --> [Postgres + pgvector]
  [Agent Workers xN] --> [Object Storage]
  [Agent Workers xN] --> [Redis Cache]
}
[Admin/Web UI] --> [API Gateway]
[Mobile App] --> [API Gateway]
[Prometheus] ..> [Agent Workers xN]
[Prometheus] ..> [Orchestrator (Temporal)]
@enduml

Agent contract
	•	Input: task_id, tenant_id, payload, tools, memory_hint.
	•	Output: status, content, citations, metrics, next_actions.
	•	JSON Schema (shared lib, strict mode):

{
  "type":"object",
  "required":["status","content"],
  "properties":{
    "status":{"enum":["ok","retry","fail"]},
    "content":{"type":"object"},
    "citations":{"type":"array","items":{"type":"string"}},
    "metrics":{"type":"object"},
    "next_actions":{"type":"array","items":{"type":"string"}}
  },
  "additionalProperties":false
}

Orchestration patterns
	•	Workflow DAG (per use case).
	•	Retries: exponential backoff, max 3 per agent step.
	•	Timeouts: hard timeout per step, global SLA per workflow.
	•	Evaluator loop: run → evaluate → refine (max 2 cycles).
	•	Checkpointing: every agent output persisted as an immutable agent_run row.

PlantUML — generic run sequence

@startuml
actor Client
participant API
participant Temporal as WF
participant "Agent Router" as AR
participant "Agent Worker" as AW
database "Postgres + pgvector" as DB
Client -> API: POST /runs
API -> WF: startWorkflow(run_id, tenant_id)
WF -> AR: nextStep(run_id)
AR -> AW: execute(agent, payload)
AW -> DB: retrieve_memory(query)
AW -> LLM Providers: prompt(...)
LLM Providers --> AW: completion
AW -> DB: persist(agent_run, embeddings)
AW --> AR: {status, content}
AR -> WF: stepResult(...)
WF -> API: stream updates
API --> Client: SSE/WebSocket events
@enduml

Data model (Postgres + pgvector)

-- Tenancy and auth
CREATE TABLE tenants (
  id uuid PRIMARY KEY, name text UNIQUE NOT NULL, created_at timestamptz DEFAULT now()
);
CREATE TABLE users (
  id uuid PRIMARY KEY, tenant_id uuid REFERENCES tenants(id),
  email citext UNIQUE NOT NULL, role text CHECK (role IN ('owner','admin','member')),
  created_at timestamptz DEFAULT now()
);

-- Work items
CREATE TABLE projects (
  id uuid PRIMARY KEY, tenant_id uuid REFERENCES tenants(id), name text NOT NULL, created_at timestamptz DEFAULT now()
);
CREATE TABLE runs (
  id uuid PRIMARY KEY, project_id uuid REFERENCES projects(id),
  kind text, status text, created_at timestamptz DEFAULT now(), updated_at timestamptz DEFAULT now()
);
CREATE TABLE agent_runs (
  id uuid PRIMARY KEY, run_id uuid REFERENCES runs(id),
  agent_name text, step int, status text, content jsonb, metrics jsonb,
  created_at timestamptz DEFAULT now()
);

-- Documents and memory
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE documents (
  id uuid PRIMARY KEY, tenant_id uuid REFERENCES tenants(id),
  project_id uuid REFERENCES projects(id), path text, mime text,
  sha256 bytea, created_at timestamptz DEFAULT now()
);
CREATE TABLE memory_chunks (
  id uuid PRIMARY KEY, tenant_id uuid REFERENCES tenants(id),
  project_id uuid REFERENCES projects(id), doc_id uuid REFERENCES documents(id),
  text text, embedding vector(1536), meta jsonb, created_at timestamptz DEFAULT now()
);
CREATE INDEX ON memory_chunks USING ivfflat (embedding vector_cosine_ops);

Retrieval and memory flow
	•	Embed prompts and chunked docs on ingest.
	•	At run time: K nearest chunks by cosine → routed into agent context.
	•	Write-ahead log for each step for auditability.

Use-case DAGs

Compliance Intelligence MVP
	1.	Ingest policy PDFs → OCR if needed → chunk + embed.
	2.	ReAct agent extracts obligations by article.
	3.	Debate agents argue applicability; Evaluator scores risk.
	4.	Planning agent proposes mitigations; Memory stores decisions.

Customer Success Intelligence MVP
	1.	Ingest tickets, CSAT, churn labels.
	2.	Tree-of-Thought explores churn hypotheses.
	3.	Multi-Agent assigns persona analyzers: sentiment, feature gaps, response lag.
	4.	Evaluator ranks interventions; Curriculum tracks learning progression.

LLM/tooling integration
	•	Providers: OpenAI or Anthropic behind an abstraction: llm.invoke(model, prompt, tools, json_mode=True).
	•	Tools: HTTP fetch, calculator, SQL read-only, file retrieval.
	•	Safety: prompt templates with strict JSON mode and schema validation on ingress.

Security model
	•	Per-tenant row-level security (RLS) on all tables.
	•	API scopes: runs:write, runs:read, documents:write, admin:*.
	•	Secrets: K8s Secret + (optional) Vault injector.
	•	PII: encrypt sensitive columns using pgcrypto or app-layer AEAD.

Sizing and scaling
	•	Start: 3 replicas API, 1 Temporal server, 3 worker deployments, HPA target 70% CPU.
	•	Vertical growth: split workers per agent class (reasoning vs retrieval heavy).
	•	Horizontal growth: shard by tenant or project.

Concrete algorithms
	•	Chunking: recursive character splitter 2k-4k chars with 10% overlap.
	•	RAG retrieval: top-8 by cosine, MMR re-rank to 5.
	•	Swarm vote: majority vote with confidence weighting; break ties via Evaluator score.
	•	Auto Loop: max 2 refine cycles; stop if Evaluator ≥ threshold.
